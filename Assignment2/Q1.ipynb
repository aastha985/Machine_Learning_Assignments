{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXjqUjZheuAe"
      },
      "source": [
        "# Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ITUkTAcWEt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dshjermBe3vo"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Hpe_ZbxPe3Ep",
        "outputId": "9934df78-d9ac-4065-83d6-47d628c43f62"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.drop(columns=['No'],inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>pm2.5</th>\n",
              "      <th>DEWP</th>\n",
              "      <th>TEMP</th>\n",
              "      <th>PRES</th>\n",
              "      <th>cbwd</th>\n",
              "      <th>Iws</th>\n",
              "      <th>Is</th>\n",
              "      <th>Ir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-21</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-21</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>4.92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-21</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>6.71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-21</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>9.84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-20</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>NW</td>\n",
              "      <td>12.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
              "0  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
              "1  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
              "2  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
              "3  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
              "4  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KEluu5wxdCZ"
      },
      "source": [
        "# Dropping Missing Value Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmISlKLlxbyk"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayRdhjcpxif1"
      },
      "source": [
        "# Encoding Categorical Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nC2LM2n1F5-"
      },
      "source": [
        "cols = ['year','cbwd']\n",
        "label_encoder = LabelEncoder() \n",
        "df[cols] = df[cols].apply(label_encoder.fit_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx5U-ZgOwgVW"
      },
      "source": [
        "y = df['month']\n",
        "X = df.drop(columns=['month'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTobKrcwmTc4"
      },
      "source": [
        "# Splitting Dataset Into Train, Validation and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juv_C9XCkT3D"
      },
      "source": [
        "def train_val_test_split(data,random_state,val_size=0.15,test_size=0.15):\n",
        "  \"\"\"\n",
        "  Train Valdiation Test split implemented from scratch. Takes the dataset,\n",
        "  val_size, test_size and random_state as parameters and returns the train,\n",
        "  validation and test sets.\n",
        "\n",
        "  Calculates the length of train, test and validation sets, shuffles the \n",
        "  dataset and returns the 3 sets.\n",
        "  \"\"\"\n",
        "  \n",
        "  shuffled_data = data.sample(frac=1,random_state=random_state)\n",
        "\n",
        "  val_size = int(len(data)*val_size)\n",
        "  test_size = int(len(data)*test_size)\n",
        "  train_size = len(data)-val_size-test_size\n",
        "\n",
        "  train = shuffled_data[:train_size]\n",
        "  val = shuffled_data[train_size:train_size+val_size]\n",
        "  test = shuffled_data[train_size+val_size:]\n",
        "\n",
        "  return train,val,test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrsU6li-ny_-"
      },
      "source": [
        "df_train, df_val, df_test = train_val_test_split(df,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCxwQVWRu2Qr"
      },
      "source": [
        "# Splitting Into X and y values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK2vSVbK7cWP"
      },
      "source": [
        "y_train = df_train['month']\n",
        "X_train = df_train.drop(columns=['month'])\n",
        "\n",
        "y_val = df_val['month']\n",
        "X_val = df_val.drop(columns=['month'])\n",
        "\n",
        "y_test = df_test['month']\n",
        "X_test = df_test.drop(columns=['month'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv63ng35pdqE"
      },
      "source": [
        "def accuracy(y_true,y_pred):\n",
        "  y_true = y_true.to_numpy()\n",
        "  return np.sum(y_true==y_pred)/len(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkAioIALsiR9"
      },
      "source": [
        "# A. Training Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X4Sp50d_Fdl"
      },
      "source": [
        "def train_predict_evaluate(model):\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"Accuracy: \",accuracy(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EwPJ2qz_hHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff17208-cb50-4755-f46c-d3e1a59b6dff"
      },
      "source": [
        "train_predict_evaluate(DecisionTreeClassifier(criterion='gini',random_state=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8227686412262494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRNVC13p_lVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1879db1d-e03b-48be-cbef-c948b7908454"
      },
      "source": [
        "train_predict_evaluate(DecisionTreeClassifier(criterion='entropy',random_state=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8305923678748204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn1evtP3GoP6"
      },
      "source": [
        "# B. Training Decision Tree Model on Different Max Depths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30oFIR6Ct8Yp"
      },
      "source": [
        "depths = [2,4,8,10,15,30]\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "for depth in depths:\n",
        "  decision_tree = DecisionTreeClassifier(criterion='entropy',max_depth=depth,random_state=0)\n",
        "  decision_tree.fit(X_train,y_train)\n",
        "  y_pred_train = decision_tree.predict(X_train)\n",
        "  y_pred_test = decision_tree.predict(X_test)\n",
        "  train_accuracy.append(accuracy(y_train,y_pred_train))\n",
        "  test_accuracy.append(accuracy(y_test,y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0VNMA9Ad4xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f04fdbe-6651-493c-aa8e-8c0947f90bb2"
      },
      "source": [
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:  [0.27528993192159007, 0.39885737744175703, 0.5873558892956108, 0.7071602066299476, 0.9573398104751805, 1.0]\n",
            "Test Accuracy:  [0.2818138272393422, 0.40268242056522435, 0.5700143701101709, 0.6501676512853265, 0.8064825163659588, 0.8305923678748204]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4tyEsNIJrKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b2eb6fe8-115b-427a-8413-2bb5da0075de"
      },
      "source": [
        "plt.plot(depths,train_accuracy,label='train accuracy')\n",
        "plt.plot(depths,test_accuracy,label='test accuracy')\n",
        "plt.xlabel(\"Depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs Depth\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzyu5DufNxrP"
      },
      "source": [
        "# C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGBkIfk9Rz3B"
      },
      "source": [
        "def random_selection(data,size=0.5):\n",
        "  \"\"\"\n",
        "  Trains the training data and returns a random 50%.\n",
        "  \"\"\"\n",
        "\n",
        "  shuffled_data = data.sample(frac=0.5)\n",
        "  return shuffled_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SOe2jVJxXdJ"
      },
      "source": [
        "def ensemble(n_estimators=100,max_depth=3):\n",
        "  \"\"\"\n",
        "  Combines 100 decision tree stumps trained on random 50% of the training data, predicts the\n",
        "  testing samples by taking mode over the predictions.\n",
        "  \"\"\"\n",
        "  predictions = []\n",
        "\n",
        "  for i in range(n_estimators):\n",
        "    data = random_selection(df_train)\n",
        "    y = data['month']\n",
        "    X = data.drop(columns=['month'])\n",
        "    decision_tree = DecisionTreeClassifier(criterion='entropy',max_depth=max_depth,random_state=0)\n",
        "    decision_tree.fit(X,y)\n",
        "    predictions.append(decision_tree.predict(X_test))\n",
        "\n",
        "  y_pred = pd.DataFrame(predictions).T.mode(axis='columns')[0]\n",
        "  y_test_ = y_test.reset_index(drop=True)\n",
        "\n",
        "  print(\"Accuracy: \",accuracy(y_test_,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuI8VcPnfnOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bceff4d-3a3f-4b73-ad45-57ad18a02f3f"
      },
      "source": [
        "ensemble()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.3557400606737985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvlzD-EwnNj"
      },
      "source": [
        "# D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMPjs1czETKE"
      },
      "source": [
        "def tuning(n_estimators=100):\n",
        "  \"\"\"\n",
        "  Function for tuning decision stump by changing max depth and n estimators.\n",
        "  Train, Validation and Test Accuracies are returned for different values\n",
        "  of max_depth and n_estimators\n",
        "  \"\"\"\n",
        "  depths = [4,8,10,15,20,30]\n",
        "  results = []\n",
        "  y_test_ = y_test.reset_index(drop=True)\n",
        "\n",
        "  #trains decision tree stumps on different depths, stores the train, test and\n",
        "  # validation predictions\n",
        "\n",
        "  for depth in depths:\n",
        "    predictions_train = []\n",
        "    predictions_val = []\n",
        "    predictions_test = []\n",
        "    for i in range(n_estimators):\n",
        "      data = random_selection(df_train)\n",
        "      y = data['month']\n",
        "      X = data.drop(columns=['month'])\n",
        "      decision_tree = DecisionTreeClassifier(criterion='entropy',max_depth=depth,random_state=0)\n",
        "      decision_tree.fit(X,y)\n",
        "      predictions_train.append(decision_tree.predict(X_train))\n",
        "      predictions_val.append(decision_tree.predict(X_val))\n",
        "      predictions_test.append(decision_tree.predict(X_test))\n",
        "\n",
        "    # takes mode over predictions to find y_pred\n",
        "    num = [4,8,10,15,20,100]\n",
        "    for n in num:\n",
        "      y_pred_train = pd.DataFrame(predictions_train[:n]).T.mode(axis='columns')[0]\n",
        "      y_pred_val = pd.DataFrame(predictions_val[:n]).T.mode(axis='columns')[0]\n",
        "      y_pred_test = pd.DataFrame(predictions_test[:n]).T.mode(axis='columns')[0]\n",
        "      accuracy_train = accuracy(y_train,y_pred_train)\n",
        "      accuracy_val = accuracy(y_val,y_pred_val)\n",
        "      accuracy_test = accuracy(y_test,y_pred_test)\n",
        "      result = {'depth':depth,\n",
        "                      'n_estimator':n,\n",
        "                      'train accuracy':accuracy_train,\n",
        "                      'validation accuracy': accuracy_val,\n",
        "                      'test accuracy': accuracy_test}\n",
        "      print(result)\n",
        "      results.append(result)\n",
        "\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2-ef7mQR0CO"
      },
      "source": [
        "def save_and_load_results():\n",
        "  if not os.path.exists(\"D_results.csv\"):\n",
        "    results = tuning()\n",
        "    res = pd.DataFrame.from_dict(results)\n",
        "    res.to_csv('D_results.csv')\n",
        "  return pd.read_csv('D_results.csv',index_col=0)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNehBZKsSWC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a912718-3df0-49f0-c296-20e73b206fa8"
      },
      "source": [
        "D_results = save_and_load_results()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'depth': 4, 'n_estimator': 4, 'train accuracy': 0.39892579795422667, 'validation accuracy': 0.38591729203257225, 'test accuracy': 0.4041194315823088}\n",
            "{'depth': 4, 'n_estimator': 8, 'train accuracy': 0.4071704697068181, 'validation accuracy': 0.4036404279099473, 'test accuracy': 0.4100271435414338}\n",
            "{'depth': 4, 'n_estimator': 10, 'train accuracy': 0.4165098696589237, 'validation accuracy': 0.4089094683059237, 'test accuracy': 0.4208845601149609}\n",
            "{'depth': 4, 'n_estimator': 15, 'train accuracy': 0.4169203927337416, 'validation accuracy': 0.4097078077598595, 'test accuracy': 0.41928788120708926}\n",
            "{'depth': 4, 'n_estimator': 20, 'train accuracy': 0.4153467209469399, 'validation accuracy': 0.4049177710362446, 'test accuracy': 0.4221619032412582}\n",
            "{'depth': 4, 'n_estimator': 100, 'train accuracy': 0.412678320960624, 'validation accuracy': 0.4015647453297142, 'test accuracy': 0.41912821331630207}\n",
            "{'depth': 8, 'n_estimator': 4, 'train accuracy': 0.6270397865280011, 'validation accuracy': 0.5958805684176912, 'test accuracy': 0.6053009739741338}\n",
            "{'depth': 8, 'n_estimator': 8, 'train accuracy': 0.634805514693305, 'validation accuracy': 0.6053009739741338, 'test accuracy': 0.6097716749161743}\n",
            "{'depth': 8, 'n_estimator': 10, 'train accuracy': 0.6404502069720502, 'validation accuracy': 0.6126456969503433, 'test accuracy': 0.6207887593804886}\n",
            "{'depth': 8, 'n_estimator': 15, 'train accuracy': 0.6476685710375971, 'validation accuracy': 0.6223854382883602, 'test accuracy': 0.624141785087019}\n",
            "{'depth': 8, 'n_estimator': 20, 'train accuracy': 0.646368581300674, 'validation accuracy': 0.6220661025067858, 'test accuracy': 0.6273351429027623}\n",
            "{'depth': 8, 'n_estimator': 100, 'train accuracy': 0.6567000786835894, 'validation accuracy': 0.6236627814146575, 'test accuracy': 0.6343605300973975}\n",
            "{'depth': 10, 'n_estimator': 4, 'train accuracy': 0.749101980773836, 'validation accuracy': 0.6870509340571611, 'test accuracy': 0.6969503432859652}\n",
            "{'depth': 10, 'n_estimator': 8, 'train accuracy': 0.7888542985186959, 'validation accuracy': 0.7264889030815903, 'test accuracy': 0.7319176113683539}\n",
            "{'depth': 10, 'n_estimator': 10, 'train accuracy': 0.7942937292600322, 'validation accuracy': 0.7359093086380329, 'test accuracy': 0.737026983873543}\n",
            "{'depth': 10, 'n_estimator': 15, 'train accuracy': 0.8069173138106804, 'validation accuracy': 0.750758422481239, 'test accuracy': 0.7456490499760499}\n",
            "{'depth': 10, 'n_estimator': 20, 'train accuracy': 0.8090383496972392, 'validation accuracy': 0.7557081270956411, 'test accuracy': 0.7515567619351748}\n",
            "{'depth': 10, 'n_estimator': 100, 'train accuracy': 0.8272039957579282, 'validation accuracy': 0.7726329235190803, 'test accuracy': 0.7672042152323167}\n",
            "{'depth': 15, 'n_estimator': 4, 'train accuracy': 0.9354452464848961, 'validation accuracy': 0.8251636595880568, 'test accuracy': 0.8131885677790196}\n",
            "{'depth': 15, 'n_estimator': 8, 'train accuracy': 0.9693134001573672, 'validation accuracy': 0.8658789717387834, 'test accuracy': 0.853744212038959}\n",
            "{'depth': 15, 'n_estimator': 10, 'train accuracy': 0.9761896616605659, 'validation accuracy': 0.8754590451860131, 'test accuracy': 0.864601628612486}\n",
            "{'depth': 15, 'n_estimator': 15, 'train accuracy': 0.9845027539256269, 'validation accuracy': 0.8879131406674118, 'test accuracy': 0.8807280855819895}\n",
            "{'depth': 15, 'n_estimator': 20, 'train accuracy': 0.9881290410865178, 'validation accuracy': 0.8962158709883442, 'test accuracy': 0.8858374580871786}\n",
            "{'depth': 15, 'n_estimator': 100, 'train accuracy': 0.9949368820772467, 'validation accuracy': 0.9105859811591889, 'test accuracy': 0.9059556123263611}\n",
            "{'depth': 20, 'n_estimator': 4, 'train accuracy': 0.9489925079538846, 'validation accuracy': 0.8267603384959284, 'test accuracy': 0.8235669806801852}\n",
            "{'depth': 20, 'n_estimator': 8, 'train accuracy': 0.981663302658137, 'validation accuracy': 0.8714673479163341, 'test accuracy': 0.8617276065783172}\n",
            "{'depth': 20, 'n_estimator': 10, 'train accuracy': 0.9877527282679347, 'validation accuracy': 0.8807280855819895, 'test accuracy': 0.8737026983873543}\n",
            "{'depth': 20, 'n_estimator': 15, 'train accuracy': 0.9936026820840889, 'validation accuracy': 0.8955771994251956, 'test accuracy': 0.8887114801213476}\n",
            "{'depth': 20, 'n_estimator': 20, 'train accuracy': 0.996031610276761, 'validation accuracy': 0.9030815902921923, 'test accuracy': 0.8957368673159828}\n",
            "{'depth': 20, 'n_estimator': 100, 'train accuracy': 0.9996921076938866, 'validation accuracy': 0.9233594124221619, 'test accuracy': 0.9148970142104422}\n",
            "{'depth': 30, 'n_estimator': 4, 'train accuracy': 0.9509082823030345, 'validation accuracy': 0.8251636595880568, 'test accuracy': 0.8167012613763373}\n",
            "{'depth': 30, 'n_estimator': 8, 'train accuracy': 0.9820054052204851, 'validation accuracy': 0.8679546543190164, 'test accuracy': 0.859651923998084}\n",
            "{'depth': 30, 'n_estimator': 10, 'train accuracy': 0.9876158872429954, 'validation accuracy': 0.8768960562030975, 'test accuracy': 0.8730640268242057}\n",
            "{'depth': 30, 'n_estimator': 15, 'train accuracy': 0.9944237282337245, 'validation accuracy': 0.8941401884081112, 'test accuracy': 0.887114801213476}\n",
            "{'depth': 30, 'n_estimator': 20, 'train accuracy': 0.9959974000205262, 'validation accuracy': 0.9018042471658949, 'test accuracy': 0.8938208526265368}\n",
            "{'depth': 30, 'n_estimator': 100, 'train accuracy': 0.9997605282063563, 'validation accuracy': 0.9230400766405876, 'test accuracy': 0.9164936931183139}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP1FHA2hYeM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d423d90-611f-432f-f3f0-ce7e2841e043"
      },
      "source": [
        "print(display(D_results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>depth</th>\n",
              "      <th>n_estimator</th>\n",
              "      <th>train accuracy</th>\n",
              "      <th>validation accuracy</th>\n",
              "      <th>test accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.398926</td>\n",
              "      <td>0.385917</td>\n",
              "      <td>0.404119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0.407170</td>\n",
              "      <td>0.403640</td>\n",
              "      <td>0.410027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0.416510</td>\n",
              "      <td>0.408909</td>\n",
              "      <td>0.420885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>0.416920</td>\n",
              "      <td>0.409708</td>\n",
              "      <td>0.419288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>0.415347</td>\n",
              "      <td>0.404918</td>\n",
              "      <td>0.422162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>0.412678</td>\n",
              "      <td>0.401565</td>\n",
              "      <td>0.419128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.627040</td>\n",
              "      <td>0.595881</td>\n",
              "      <td>0.605301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0.634806</td>\n",
              "      <td>0.605301</td>\n",
              "      <td>0.609772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>0.640450</td>\n",
              "      <td>0.612646</td>\n",
              "      <td>0.620789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>0.647669</td>\n",
              "      <td>0.622385</td>\n",
              "      <td>0.624142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>0.646369</td>\n",
              "      <td>0.622066</td>\n",
              "      <td>0.627335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>0.656700</td>\n",
              "      <td>0.623663</td>\n",
              "      <td>0.634361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.749102</td>\n",
              "      <td>0.687051</td>\n",
              "      <td>0.696950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0.788854</td>\n",
              "      <td>0.726489</td>\n",
              "      <td>0.731918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0.794294</td>\n",
              "      <td>0.735909</td>\n",
              "      <td>0.737027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0.806917</td>\n",
              "      <td>0.750758</td>\n",
              "      <td>0.745649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>0.809038</td>\n",
              "      <td>0.755708</td>\n",
              "      <td>0.751557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.827204</td>\n",
              "      <td>0.772633</td>\n",
              "      <td>0.767204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0.935445</td>\n",
              "      <td>0.825164</td>\n",
              "      <td>0.813189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>0.969313</td>\n",
              "      <td>0.865879</td>\n",
              "      <td>0.853744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.875459</td>\n",
              "      <td>0.864602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>0.984503</td>\n",
              "      <td>0.887913</td>\n",
              "      <td>0.880728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>0.988129</td>\n",
              "      <td>0.896216</td>\n",
              "      <td>0.885837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>15</td>\n",
              "      <td>100</td>\n",
              "      <td>0.994937</td>\n",
              "      <td>0.910586</td>\n",
              "      <td>0.905956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.948993</td>\n",
              "      <td>0.826760</td>\n",
              "      <td>0.823567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>0.981663</td>\n",
              "      <td>0.871467</td>\n",
              "      <td>0.861728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>0.987753</td>\n",
              "      <td>0.880728</td>\n",
              "      <td>0.873703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>0.993603</td>\n",
              "      <td>0.895577</td>\n",
              "      <td>0.888711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.996032</td>\n",
              "      <td>0.903082</td>\n",
              "      <td>0.895737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>0.999692</td>\n",
              "      <td>0.923359</td>\n",
              "      <td>0.914897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>0.950908</td>\n",
              "      <td>0.825164</td>\n",
              "      <td>0.816701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>0.982005</td>\n",
              "      <td>0.867955</td>\n",
              "      <td>0.859652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>0.987616</td>\n",
              "      <td>0.876896</td>\n",
              "      <td>0.873064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>0.994424</td>\n",
              "      <td>0.894140</td>\n",
              "      <td>0.887115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>0.995997</td>\n",
              "      <td>0.901804</td>\n",
              "      <td>0.893821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>30</td>\n",
              "      <td>100</td>\n",
              "      <td>0.999761</td>\n",
              "      <td>0.923040</td>\n",
              "      <td>0.916494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    depth  n_estimator  train accuracy  validation accuracy  test accuracy\n",
              "0       4            4        0.398926             0.385917       0.404119\n",
              "1       4            8        0.407170             0.403640       0.410027\n",
              "2       4           10        0.416510             0.408909       0.420885\n",
              "3       4           15        0.416920             0.409708       0.419288\n",
              "4       4           20        0.415347             0.404918       0.422162\n",
              "5       4          100        0.412678             0.401565       0.419128\n",
              "6       8            4        0.627040             0.595881       0.605301\n",
              "7       8            8        0.634806             0.605301       0.609772\n",
              "8       8           10        0.640450             0.612646       0.620789\n",
              "9       8           15        0.647669             0.622385       0.624142\n",
              "10      8           20        0.646369             0.622066       0.627335\n",
              "11      8          100        0.656700             0.623663       0.634361\n",
              "12     10            4        0.749102             0.687051       0.696950\n",
              "13     10            8        0.788854             0.726489       0.731918\n",
              "14     10           10        0.794294             0.735909       0.737027\n",
              "15     10           15        0.806917             0.750758       0.745649\n",
              "16     10           20        0.809038             0.755708       0.751557\n",
              "17     10          100        0.827204             0.772633       0.767204\n",
              "18     15            4        0.935445             0.825164       0.813189\n",
              "19     15            8        0.969313             0.865879       0.853744\n",
              "20     15           10        0.976190             0.875459       0.864602\n",
              "21     15           15        0.984503             0.887913       0.880728\n",
              "22     15           20        0.988129             0.896216       0.885837\n",
              "23     15          100        0.994937             0.910586       0.905956\n",
              "24     20            4        0.948993             0.826760       0.823567\n",
              "25     20            8        0.981663             0.871467       0.861728\n",
              "26     20           10        0.987753             0.880728       0.873703\n",
              "27     20           15        0.993603             0.895577       0.888711\n",
              "28     20           20        0.996032             0.903082       0.895737\n",
              "29     20          100        0.999692             0.923359       0.914897\n",
              "30     30            4        0.950908             0.825164       0.816701\n",
              "31     30            8        0.982005             0.867955       0.859652\n",
              "32     30           10        0.987616             0.876896       0.873064\n",
              "33     30           15        0.994424             0.894140       0.887115\n",
              "34     30           20        0.995997             0.901804       0.893821\n",
              "35     30          100        0.999761             0.923040       0.916494"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBtw_rjpO9BY"
      },
      "source": [
        "# E."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuPi2hpDnTMV"
      },
      "source": [
        "#### Adaboost with Decision Tree as base estimator and different n_estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW68RKmkO8Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b63b625-98e2-4200-b682-7a9aa2b0478d"
      },
      "source": [
        "number_of_estimators = [4,8,10,15,20]\n",
        "\n",
        "for num in number_of_estimators:\n",
        "  ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',random_state=0),n_estimators=num)\n",
        "  ada_boost.fit(X_train,y_train)\n",
        "  y_pred = ada_boost.predict(X_test)\n",
        "  print(\"Accuracy Score for n_estimators = \"+str(num)+\": \"+str(accuracy(y_test,y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score for n_estimators = 4: 0.8286763531853745\n",
            "Accuracy Score for n_estimators = 8: 0.8323487146734792\n",
            "Accuracy Score for n_estimators = 10: 0.8336260577997765\n",
            "Accuracy Score for n_estimators = 15: 0.8315503752195433\n",
            "Accuracy Score for n_estimators = 20: 0.8318697110011177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrYFbSE19nFQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}